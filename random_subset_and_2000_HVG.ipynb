{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from anndata import AnnData\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from paste import pairwise_align\n",
    "import ot\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Linear(10,10).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_index = [25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 149, 151, 153, 155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取切片的子集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subset(adata,cell_num=1200):\n",
    "    '''\n",
    "    随机选取 12,00 个细胞\n",
    "    '''\n",
    "    \n",
    "    random_indices = np.random.choice(adata.n_obs, cell_num, replace=False)   # 从 276593 个细胞中随机选取 3000 个细胞的索引\n",
    "    adata_subset = adata[random_indices, :]   # 使用选取的索引创建新的 AnnData 对象\n",
    "\n",
    "    return adata_subset\n",
    "\n",
    "# slice_0_subset = random_subset(slice_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [02:31<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "h5ad_dic = '/home/hanyuji/Data/ST_data/macaque_cortex/h5ad/'\n",
    "# files = 'total_gene_T25.type20230503-macaque1-contour2.h5ad'\n",
    "\n",
    "data_index = all_index\n",
    "# data_index = [153, 155]\n",
    "\n",
    "subset_dir = '/home/hanyuji/Data/ST_data/macaque_cortex/cortex_subset_1200_spot_h5ad/'\n",
    "\n",
    "adatas = []\n",
    "for index in tqdm(data_index):\n",
    "    data_path = h5ad_dic + f'total_gene_T{index}.type20230503-macaque1-contour2.h5ad'\n",
    "    adata = sc.read_h5ad(data_path)\n",
    "    \n",
    "    # 简单的预处理\n",
    "    adata.obs['slice_index'] = np.repeat(index, adata.n_obs)  # 添加切片序号信息\n",
    "    adata.obsm['spatial_raw'] = adata.obsm['spatial'].copy()  # 复制obsm['spatial']中的数据\n",
    "    adata.obsm['spatial'] = np.delete(adata.obsm['spatial'], [0, 1], axis=1)  # 删除obsm['spatial']中的前两列\n",
    "    \n",
    "    adata_subset = random_subset(adata)\n",
    "    # adata_subset.write(subset_dir + f'macaque1_cortex_T{index}_12000spot_total_gene.h5ad') # 保存切片子集\n",
    "    \n",
    "    adatas.append(adata_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1428000 × 15929\n",
       "    obs: 'chip', 'gene_area', 'slice_index', 'batch'\n",
       "    obsm: 'spatial', 'spatial_raw'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并切片adata\n",
    "\n",
    "combined_adata = ad.concat(\n",
    "    adatas, \n",
    "    axis=0, \n",
    "    join='outer', \n",
    "    merge='unique', \n",
    "    uns_merge='unique', \n",
    "    label='batch', \n",
    "    keys=list(range(len(adatas))), \n",
    "    index_unique='-', \n",
    "    fill_value=0\n",
    ")\n",
    "combined_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算高可变基因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice_HVG(slice, n_top_genes=2000, need_norm_and_log1p=False, target_sum=1e4):\n",
    "    '''\n",
    "    计算并选择前2000个高可变基因\n",
    "    '''\n",
    "    \n",
    "    slice.var_names_make_unique()  # 确保变量名唯一，避免重复\n",
    "    sc.pp.filter_genes(slice, min_counts=5)  # 过滤掉计数小于5的基因\n",
    "    sc.pp.highly_variable_genes(slice, n_top_genes=n_top_genes, flavor='seurat')  # 使用seurat_v3方法计算高可变基因，并选择前3000个\n",
    "    slice = slice[:, slice.var.highly_variable]  # 只保留高可变基因\n",
    "    \n",
    "    if need_norm_and_log1p:\n",
    "        sc.pp.normalize_total(slice, target_sum=target_sum)  # 将每个细胞的总表达量归一化为10000\n",
    "        sc.pp.log1p(slice)  # 对数据进行对数变换\n",
    "    \n",
    "    return slice  # 返回处理后的数据\n",
    "\n",
    "\n",
    "adatas_HVG = get_slice_HVG(combined_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/hanyuji/Workbench/ST/ST_data_check/paste_alignment_cortex/PASTE_align/cortex_macaque1_119slice_subset_1200spot_2000gene_HVG.h5ad'\n",
    "adatas_HVG.write(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5000 subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_HVG_path = '/home/hanyuji/Workbench/ST/ST_data_check/paste_alignment_cortex/PASTE_align/cortex_macaque1_119slice_subset_12000spot_2000gene_HVG.h5ad'\n",
    "\n",
    "adata = sc.read_h5ad(dataset_HVG_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据batch值分开成多个AnnData对象\n",
    "unique_batches = adata.obs['batch'].unique()\n",
    "\n",
    "adata_list = [random_subset(adata[adata.obs['batch'] == batch].copy(),cell_num=1000) for batch in unique_batches]\n",
    "# adata_list = [adata[adata.obs['batch'] == batch].copy() for batch in unique_batches]\n",
    "\n",
    "# 保存切片subset\n",
    "subset_combined_adata = ad.concat(\n",
    "    adata_list, \n",
    "    axis=0, \n",
    "    join='outer', \n",
    "    merge='unique', \n",
    "    uns_merge='unique', \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "dataset_HVG_subset_path = '/home/hanyuji/Workbench/ST/ST_data_check/paste_alignment_cortex/PASTE_align/cortex_macaque1_119slice_subset_1000spot_2000gene_HVG.h5ad'\n",
    "subset_combined_adata.write(dataset_HVG_subset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PASTE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
